akka {

  # Logging
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logLevel = "DEBUG"
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  log-dead-letters = 10
  log-dead-letters-during-shutdown = off
  log-config-on-start = off

  actor.provider = "akka.cluster.ClusterActorRefProvider"

  # For multiple node container configuration, need to remove the remote hostname and port so that AKKA will
  # directly use the IP address of the container.
  # remote.netty.tcp.port=0
  # remote.netty.tcp.hostname=127.0.1.1

  remote.netty.tcp.port=0
  remote.netty.tcp.hostname=127.0.1.1


  #  remote {
  #    netty.tcp {
  #      # hostname = my.domain.com      # external (logical) hostname
  #      # port = 8000                   # external (logical) port

  #      bind-hostname = local.address # internal (bind) hostname
  #      bind-port = 0                 # internal (bind) port
  #    }
  #  }


  scheduler {
    tick-duration = 10ms
    ticks-per-wheel = 2
  }

  cluster {
    #seed-nodes = [
      #In production configuration, need to replace the IP address with real IP addresses from cluster nodes.
      #"akka.tcp://ClusterSystem@172.17.0.3:2551",
      #"akka.tcp://ClusterSystem@127.0.1.1:2551",
      #"akka.tcp://ClusterSystem@192.168.0.106:2551",
      #"akka.tcp://ClusterSystem@127.0.0.1:2552",
      #"akka.tcp://ClusterSystem@127.0.0.1:2553"seed-ip
    #  ]

    #seed-nodes = [
    #  "akka.tcp://"${clustering.clustername}"@"${clustering.seed-ip}":"${clustering.seed-port}
    #]
      #auto-down-unreachable-after = 10s
  }

  extensions = ["akka.cluster.pubsub.DistributedPubSub", "akka.cluster.client.ClusterClientReceptionist"]

  #persistence {
  #  journal.plugin = "akka.persistence.journal.leveldb-shared"
  #  journal.leveldb-shared.store {
      # DO NOT USE 'native = off' IN PRODUCTION !!!
  #    native = off
  #    dir = "target/shared-journal"
  #  }
  #  snapshot-store.plugin = "akka.persistence.snapshot-store.local"
  #  snapshot-store.local.dir = "target/snapshots"
  #}

  persistence {
    journal {
      plugin = "cassandra-journal"
      # Comma-separated list of contact points in the cluster
      cassandra-journal.contact-points = ["dse-9042.service.consul"]
    }

    snapshot-store {
      #plugin = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"
      plugin = "cassandra-snapshot-store"
      # Comma-separated list of contact points in the cluster
      cassandra-journal.contact-points = ["dse-9042.service.consul"]
    }
  }

  actor {
    serializers {
      java = "akka.serialization.JavaSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
      #jacksonSmile = "com.rampbot.cluster.messages.serialization.JacksonSmileSerializer"
      #shapeTransactionJsonSerializer = "com.rampbot.cluster.messages.serialization.JacksonSmileSerializer"
      #shapeJsonSerializer = "com.rampbot.cluster.messages.serialization.JacksonSmileSerializer"
    }

    serialization-bindings {
      "java.lang.String" = java
      #"docs.serialization.Customer" = java
      #"com.rampbot.cluster.messages.AkkaMessageBase" = jacksonSmile
      #"com.rampbot.cluster.messages.RegisterNodeManager" = jacksonSmile
      #"com.google.protobuf.Message" = proto
      #"com.rampbot.map.datatypes.shapes.Shape" = shapeJsonSerializer
      #"com.rampbot.map.datatypes.shapes.ShapeTransaction" = shapeTransactionJsonSerializer
      #"com.rampbot.cluster.spacecoordinator.persistence.TransactionState" = shapeTransactionJsonSerializer
      #"com.rampbot.cluster.messages.utils.AtLeastOnceDeliveryHelper" = java
    }
    default-dispatcher.throughput = 100
    default-dispatcher.fork-join-executor.parallelism-factor = 2
    default-dispatcher.fork-join-executor.parallelism-min = 4
    default-dispatcher.fork-join-executor.parallelism-max = 64
  }
}

leveldb {
  dir = "target/persistence/journal"
  checksum: "off"
  class: "akka.persistence.journal.leveldb.LeveldbJournal"
  dir: "target/persistence/journal"
  fsync: "on"
  native: "on"
  plugin-dispatcher : "akka.persistence.dispatchers.default-plugin-dispatcher"
  replay-dispatcher : "akka.persistence.dispatchers.default-replay-dispatcher"
}

emu-io-dispatcher {
  #type = PinnedDispatcher
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = 2048
    allow-core-timeout = on
  }
  throughput = 100
}

io-dispatcher {
  #type = PinnedDispatcher
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = 8
    allow-core-timeout = on
  }
  throughput = 3000
}

high-throughput-dispatcher {
  #type = PinnedDispatcher
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = 8
    allow-core-timeout = on
  }
  throughput = 1000
}